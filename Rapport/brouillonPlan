Page de garde

* Abstract
* Sommaire
* Introduction
  ** Pourquoi ce projet
     *** Petite partie sur les projets identiquesPROJETS SIMILAIRES
         .http://www.ictjournal.ch/fr-CH/News/2013/11/08/KeyLemon-entre-dans-votre-voiture.aspx
La caméra regarde où regarde le chauffeur. Et un radar est utilisé pour détecter les piétons. Identifie le conducteur et règle le siège, rétro, ...
         .http://www.gentside.com/denso/un-systeme-de-reconnaissance-faciale-detecte-la-somnolence-au-volant_art31705.html
Denso détecte si le conducteur s'endort et possède 6 phases de notifications. La détection se fait à l'aide de 17 points sur le visage
         .http://www.lemondeinformatique.fr/actualites/lire-ceatec-la-voiture-de-demain-diagnostiquera-le-conducteur-55202.html
Alps Electric comme le premier projet. Identifie le conducteur et règle + bilan de santé + reconnaissance de la main
         .http://www.generation-nt.com/toyota-fv2-concept-voiture-capable-lire-emotions-conducteur-actualite-1810542.html
change la couleur du véhicule selon l'humeur du conducteur + pare brise avec réalité augmentée
  ** Histoire de la reconnaissance Faciale
     *** Ekman
* Reconnaissance Faciale
  ** Théorie
     *** Général
         . Enormément de méthodes, on peut aussi combiner avec des méthodes telles que la mise en place d'un réseau neuronnal (mais en 3 mois, pas le temps).
         . On traite des images en n&b car la colorimétrie n'est pas importante.
     *** Eigenface
     *** FisherFace
     *** LBPH
         . Méthode:
Consiste à regarder le niveau d'un pixel par rapport à ses voisins. 
La première étape consiste à diviser l'image en groupes de pixels. 
Le pixel choisit sert de base pour effectuer un seuil avec les voisins (grâce à la fonction d'Heaviside. Qui dit 0 si x<0, 1 sinon. Ici on a 0 si x<pixel de base 1 sinon). 
Puis une pondération de chaque pixel donne une valeur.
Chaque groupe est passé à cette pondération. 
Toutes les valeurs sont mises les unes à la suite des autres pour former l'histogramme de l'image.
Il ne reste plus qu'à faire la différence entre deux histogrammes.
         . Un algo très utilisé
Cette algo est très utilisé comme dans :
TITRE: 
Facial expression recognition based on Local Binary Patterns:A comprehensive study
AUTEURS:
Caifeng Shan a, * , Shaogang Gong b , Peter W. McOwan b
Ou il est combiné avec Adaboost pour obtenir de meilleurs résultats + un réseau neuronnal
Ou TITRE:
Face Recognition with Local Binary Patterns, Spatial Pyramid Histograms and
Naive Bayes Nearest Neighbor classification
AUTEURS:
Daniel Maturana, Domingo Mery and Alvaro
Soto
où les auteurs essayent d'améliorer l'algo pour obtenir le leur : NNBN que nous n'utiliserons pas (temps, et LBPH est déjà intégré dans OpenCV)
  ** Expérimentations
     *** Protocole
         . Le but de cette expérimentation était de comparer les 3 méthodes implémentées par la librairie OpenCV pour voir laquelle on pouvait choisir pour l'application finale puis de voir la robustesse de cette méthode.
         . On a donc réaliser 2 expériences. La première pour regarder la vitesse selon le nombre de photos de bases. Puis de comparer le %age de réussite.
         . La seconde pour regarder la robustesse (grimaces, visage caché, rotation, ...).
     *** Réalisation Expérience 1
         . On a regardé deux vitesses. Le temps de la construction du modèle puis le temps pour réaliser la reconnaissance.
         . On a donc capturé une photo pour servir de base. La base de données était composée de 3 individus.
         . Puis pour chaque algo, et pour éviter au max les impressisions due au processeur qui ne travaille pas toujours pareil on a passé l'image pour chaque algo 100 fois (puis on a fais la moyenne pour avoir le temps moyen) sur le même ordinateur.
         . On a donc testé 3 algos (Eigenface, fisherface, LBPH) avec une image de base, avec une base de données de 3 individus avec le nombre de photo suivant : 1,2,4,6,8,10,12.
     *** Résultats & Analyse Expérience 1
         . Refaire les graphes avec latex
         . Pour le temps de création du modele. FisherFace est le plus rapide. Puis EigenFace (qui deviens de plus en plus lent jusqu'à rattraper LBPH au bout de 36 photos). LBPH reste le plus lent.
         . Pour la reconnaissance des visages, la durée reste la même avec environ 680<->690 ms avec un processeur i5 2 eme génération pour les 3 algos.
         . Ainsi on remarque que le temps n'est pas le principal facteur. Si on prend LBPH, l'initialisation du système sera un peu plus longue, mais le temps de reconnaissance restera identique le reste de l'application.
     *** Réalisation Expérience 2
         . Pour déterminer le meilleur algorithme, on a donc :
         . Pris une vidéo de 100 frames ou l'individu bouger la tête.
         . Enregistré l'individu avec 12 photos dans la base de données.
         . Passé la vidéo aux 3 algos pour voir le %age de reconnaissance.
     *** Résultats & Analyse Expérience 2
         . Refaire les graphes avec latex
         . Amaury : Eigenface = 71.929824561404% / fisherface = 59.649122807018% / LBPH = 82.456140350877%
Phenri : Eigenface = 7.4074074074074% / fisherface = 80.246913580247% / LBPH = 60.493827160494%
Seb : Eigenface = 24.657534246575% / fisherface = 73.972602739726% / LBPH = 90.41095890411%
         . On remarque que LBPH est globalement le meilleur des 3. Puis vient FisherFace puis EigenFace loin derrière.
     *** Réalisation Expérience Robustesse
         . On a donc choisit LBPH
         . Pour la robustesse on a demandé à plusieurs personnes de s'enregistrer dans la base de données.
         . Puis de prendre une vidéo de 100 frames.
         . On a donc pris différente personne sous :
           .. différentes luminosité (élevée, naturelle, faible)
           .. différentes orientation de la tête
           .. différentes inclinaison
           .. différentes déformation du visage
           .. différentes parties cachées du visage   
           .. différentes distances
     *** Résultats & Analyse Robustesse
!!!!!!BESOIN DE PHOTOS, JE M'EN OCCUPE (SEB) + PH SI TU AS ES PARTIES DU VISAGE CACHEES!!!!!!!!       
         . On en a donc déduit
           .. différentes luminosité (élevée, naturelle, faible) : La luminosité peut être un probleme lorsque les yeux sont trop cachés par la lumièce ou lorsque la limite face/décor est difficile à voir).
           .. différentes orientation de la tête (limite d'environ 20°, il faut au moins garder les deux yeux bien visible)
           .. différentes inclinaison (idem)
           .. différentes déformation du visage (pas de problème). Des accessoires telles que des lunettes ne changent pas beaucoup le résultat, mais le mieux reste de prendre des photos dans la base de données avec plusieurs accessoires.
           .. différentes parties cachées du visage (réussite amoindrie lorsque l'on cache la bouche mais réalisable). Si on cache les yeux, la reconnaissance est impossible (embettant pour les cheveux longs)
           .. différentes distances (On perd énormément de réussite lorsque la taille du visage reconnue est plus petite que celle dans la base de données).
           .. La réalisation d'autres classifiers pour améliorer la reconnaissance pourrait être intéressant.
* Reconnaissance des émotions
  ** Théorie
     *** Différentes solutions
TODO     . contours bouche, couleur, ...
     *** Solution choisie
         . La solution qu'on a choisie est une méthode un peu différente de celle présentée. Le tracking de points ou les réseaux neuronaux demandent énormément de calcul. On doit se baser dans le cas d'une voiture, donc d'un ordinateur de bord, sans doute moins puissant qu'un pc de bureau. Pour simplifier les calculs voilà la méthode qu'on utilise pour la reco des émotions :
         . On obtient le visage. L'identité de la personne ne nous intéresse pas (on vérifie si la personne est autorisée au départ)
         . Avec un second classifier, on obtient la position des yeux. On enlève tous ceux que l'application peut trouver dans la partie basse du visage qui correspond à des erreurs. Pour ces yeux on récupère la hauteur du classifier pour savoir si les yeux sont froncés, équarquillés ou normaux). Pour détecter les yeux fermés, On regarde le nombre de pixels ayant une couleur entre (80, 0,0), (160,100,100).
         . Pour la bouche, la méthode est presque identique. Avec un classifier on récupère les bouches disponibles et on enlève les bouches impossibles (celles dans la partie haute du visage ou trop prêt du bord). Puis on converti la bouche en niveaux de gris et on effectue un seuil pour n'obtenir que l'intérieur de la bouche. Si y a de l'intérieur au-dessus du seuil de la bouche fermée c'est quelle est ouverte.
  ** Expérimentations
TODO ici on parle des protocoles fait à l'arrêt
     *** Protocole
     *** Réalisation
     *** Résultats & Analyse
* Production
  ** Prototype Final réalisé
     . Dire que le code est dispo en annexe
     . Schéma de l'arduino
     . Le prototype est fonctionnel sous linux/windows/mac (quelques problèmes de dépendances)/BSD)
     . Le prototype n'est pas fonctionnel sous Rasbpy ni Beaglebone à cause d'une fonction non portée (createLBPHFaceRecognizer), et on avait pas le temps de se pencher sur le probleme.
  ** Tests finaux
     *** Protocole
  ** Discussion & Analyse des résultats
     . Marche pour inatentif
     . Lent pour endormi (5/15 secondes)
     . Marche pour énervé & surpris, mais lent.
     . Qualité de la caméra à revoir
     . Placement de la caméra aussi, le volant gêne beaucoup
     . Ne supporte pas les changements de luminosité (le conducteur devient tout blanc, dur de trouver le visage).
     . TODO CONTINUER
* Conclusion
  ** Bilan/synthèse
     *** Réponse à la problématique
     *** Compétences acquises
         . travail de groupe
         . techniques de communication
         . git
         . python 2 car python 3 mal supporté pour la reconnaissance faciale d'opencv
         . opencv
         . php
  ** Ouverture
     *** Utilité
         . Plus comme gadget, endormi/inattentif/reconnaissance du conducteur pour éviter un vol, couleur en fonction de l'humeur, même si reconnaissance faible (une photo suffit pour contourner le systeme), les émotions sont peu fiables car peuvent provenir de beaucoup de sources.
         . Compléter plus avec radars/caméras vers l'extérieur.
--- Annexes ---
* Code des applications
* Bibliographie

