Deuxième partie : La reconnaissance faciale

Dans cette deuxieme partie, nous nous pencherons sur la reconnaissance faciale. Dans un premier temps, nous étudierons l'aspect théorique de la reconnaissance, puis  l'aspect expérimental.

Partie 1 : Théorie

Afin d'étudier l'aspect théorique de la reconnaissance faciale, nous allons d'abord l'aborder de façon général. Ensuite, nous analyserons plus en détail différentes méthodes de reconnaissance : Eighenface, Fisherface et LBPH.

Sous-partie 1 : Généralités

Après des recherches approfondies, nous avons pu constater qu'il existe énormément de méthodes possibles pour reconnaître un visage.  Ces méthodes peuvent également être combinées entre elles (par exemple, la mise en place en place d'un réseau neuronnal ##explication peut-être ?##). Cependant, en trois mois, nous nous n'aurions pas eu le temps de mettre en place une telle méthode.

Par ailleurs, nous avons choisi de traiter uniquement des images en noir et blanc, car la colorimétrie a très peu d'impact dans le processus de reconnaissance.

Sous-partie 2 : La méthode Eighenface

La méthode de reconnaissance faciale Eighenface a pour particularité de se baser sur des "eighen vectors", c'est-à-dire des vecteurs propres.

L'algorithme est le suivant : chaque image est considérée comme un vecteur avec pour dimension son nombre de pixels. Puis, un ou plusieurs algorithmes recherchent les principales composantes //--plus de précision sur composante ?--//. A l'aide de plusieurs images du même visage, nous pouvons alors composer une image du visage "moyen" qui contiendra également les principales composantes (l'eighenface). La méthode de reconnaissance des axes principaux est détaillée ici : Matthew Turk and Alex Pentland. Eigenfaces for recognition. J. Cognitive Neuroscience. 3(1) :71{86, 1991}. Enfin, il suffit de comparer l'eighenface et les composantes principales d'une capture d'un visage.

L'avantage de cette méthode est la connaissance de son existence depuis longtemps. Cependant, elle présente également des désavantages non-négligeables. En effet, comme chaque pixel est une dimension, une image 100*100 donne 10000 vecteurs à traiter. Le nombre de données à analyser est donc trop important.

Sous-partie 3 : La méthode Fisherface

La méthode de reconnaissance faciale Fisherface se base sur les travaux de Sir R.A. Fisher. L'idée de base de l'algorithme est la suivante : toutes les images qui se ressemblent, se retrouvent proches. Concrètement, imaginons un espace d'images comprenant une échelle représentant les visages. Si nous projettons les images sur l'échelle, nous pouvons dire que //-- je n'ai pas compris la suite --//

Figure présente dans le dossier image.

Pour plus de détails : http://docs.opencv.org/modules/contrib/doc/facerec/facerec_tutorial.html#fisherfaces.

Globalement, cette méthode présente les mêmes avantages et inconvénients que la méthode Eighenface. Cependant, elle est moins sensible à la lumière et à la déformation des visages car elle ne se base pas sur des composantes discriminatoires.

Sous-partie 4 : La méthode LBPH

La méthode de reconaissance faciale LBPH (Local Binary Patterns Histogram) consiste à visualiser la valeur d'un pixel (moyenne des trois composantes RGB) par rapport aux pixels voisins.

Pour commencer, l'image est divisé en groupe de pixels. Chaque groupe de pixels correspond à une matrice carré contenant les valeurs des pixels. Puis, le pixel placé au centre de la matrice est choisi comme valeur de référence. Ensuite, toutes les valeurs de la matrice sont remplacées soit par 0, soit par 1 en fonction de leur valeur. La fonction d'Heaviside, nous dit que pour tout x appartenant aux réels, H(x)=0 si x<=0, 1 sinon. Ici, si nous attribuons la valeur 0 si la valeur du pixel est inférieur à la valeur du pixel de référence, 1 sinon. Après cette opération, chaque pixel du groupe est pondéré avec un poinds plus ou moins fort (le pixel en haut à gauche a le poids le plus faible, tandis que le pixel en bas à droite a le poids le plus fort). Ainsi, nous obtenons un nombre binaire qui donne une certaine valeur en base 10. Tous les groupes de l'image sont soumis à ce processus pour finalement obtenir un histogramme de l'image. Enfin, il ne reste plus qu'à faire la différence entre deux histogrammes pour comparer deux images.

Cet algorithme est très utilisé comme nous pouvons le voir dans : Facial expression recognition based on Local Binary Patterns:A comprehensive study de Caifeng Shan a, * , Shaogang Gong b , Peter W. McOwan b, où il est combiné avec Adaboost (plugin d'openCV) pour obtenir de meilleurs résultats, et un réseau neuronnal. Mais aussi dans : Face Recognition with Local Binary Patterns, Spatial Pyramid Histograms and Naive Bayes Nearest Neighbor (NBNN) classification de Daniel Maturana, Domingo Mery and Alvaro Soto où les auteurs essayent d'améliorer l'alogrithme dans le but d'en créer un nouveau : NBNN. Nous n'utiliserons pas cet algorithme par manque de temps, mais également car LBPH est déjà présent dans openCV.

Comme nous venons de le voir, il existe différents méthodes 


Partie 2 : Expérimentations




